## Непрерывные распределения.   
Предположим, что выборочное пространство - это действительная прямая. $\omega$ - действительные числа.   
Разбивая $\Omega$ на мелкие части, приходим к бесконечно малым.   

$$M[\varepsilon_{\omega}] = \int \varepsilon_{\omega} P (d \omega)$$  
## Характеристики случайных величин   
**Определение:** Момент к-го порядка случайной величины $\varepsilon$
$$v_k = M[\varepsilon - a]^k$$  
**Определение:** Если $a = 0$, то момент называется начальным и обозначается $m_k$.   
**Определение:** Если $a = M \epsilon$, то момент называется центральным и обозначается:  
$$\mu_k = M[\varepsilon - M\varepsilon]^k$$  
**Определение:** Центральный момент второго порядка есть дисперсия случайной величины:  
$$\mu_2 = D[\varepsilon] = M[\varepsilon - M\varepsilon] ^2$$    
## Свойства дисперсии  
Дисперсия характеризует рассеивание значений случайной величины вокруг центра (математического ожидания).   
Свойства:  
1. $D [\varepsilon] \geq 0$   
2. $D[c] = 0, c = const$  
3. $D[c\varepsilon] = c^2 D[\varepsilon]$  
4. $D[\varepsilon_1 + \varepsilon_2] = D[\varepsilon_1] + D[\varepsilon_2]$  
   для независимых величин!  

## О моментах  
Между начальными и центральными моментами существует простая связь:  
$m_1, m_2, m_3,\dots$ зная центральные моменты можно посчитать все начальные.  
$$\mu_n = M[\varepsilon - M \varepsilon]^n = \sum_{k=0}^{n}C_n^k (-M\varepsilon)^{n-k} M\varepsilon^k = \sum_{k=0}^{n}C_n^k(-M\varepsilon)^{n-k}m_k$$ с учетом $m_1 = M\varepsilon$ получим:  
$$\mu_n = \sum_{k=2}^n(-1)^{n-k}C_n^km_km_1^{n-k} + (-1)^{n-1}(n-1)m_1^n$$  
$$\to \mu_0 = 1, \mu_1 = 0, \mu_2 = m_2 - m_1^2, \mu_3 = m_3-3m_2m_1+2m_1^3$$  
**Определение:** Величина $M[\varepsilon - a]^k$ называется абсолютным моментом порядка k.  
## Функция распределения  
Рассмотрим ситуацию когда $A_1 \subset A_2$  
$\to$ Можно вычислить вероятность $A_2 - A_1$  
$$P(A_1) + P(A_2 + A_1) = P(A_2)$$  В более общем виде $A_1 \subset A_2 \subset \dots \subset A_n = \Omega$  
Речь идет о вероятностях $B_1 = A_1$ и $A_i - A_{i-1}$  
Это позволяет перейти к непрерывным областям посредством введения $A(x) = \{x:\varepsilon < x\}, x \in R$  
Это означает, что для $\varepsilon_\omega$ задана функция распределения $F(x) = P(\varepsilon_\omega < x)$  
## Свойства функций распределения  
A(x) монотонно возрастает по x, что по сути есть непрерывный аналог $A_1 \subset A_2 \subset \dots$  
$$\to P(x-h \leq \varepsilon_\omega< x) = F(x) - F(x - h)$$  
1. $F(-\infty) = 0, F(+\infty) = 1$  
2. Если $x_1 < x_2$, то $F(x_1) \leq F(x_2)$  
3. $\lim_{x\to-\infty} F(x) = F(-\infty) = 0, \lim_{x\to+\infty} F(x) = F(+\infty) = 1$  
4. $\lim_{x\to x_0 -}F(x) = F(x_0)$  
5. Функция распределения может иметь не более чем счетное множества скачков.  
## Функция плотности  
Для непрерывных распределений (непрерывных случайных величин) можно использовать:  
$$ f(x) = \frac{dF(x)}{dx}$$   
$$\text{или }F(x) = \int_{-\infty}^x f(u)du$$  
Свойства:  
1. $f(x) \geq 0$  
2. $P(x_1 \leq \varepsilon < x_2) = \int_{x_1}^{x_2}f(u)du$  
    $\text{ где } x_1, x_2 \in R$  
3. $\int_{\Omega} f(u)du = 1$  
## Условное математическое ожидание  
Вычисление математического ожидания по $A \subset \Omega$  
Другими словами, при наблюдении вместо $\omega$ можно указать только множество исходов $A$.  
**Пример:** Диагностика неисправности устройства. Постановка диагноза больному.  
$$M[\varepsilon | A] = \frac{M[\varepsilon I_a]}{M[I_A]} = \frac{M[\varepsilon I_A]}{P(A)}$$  
+ Наличие индикатора $I$ в числителе означает, что усреднение идет не по всей $\Omega$   
+ Наличие индикатора $I$ в знаменателе нужно для выполнения условия нормировки $M[1|A] = 1$  
Теорема: Если $P(a) \geq 0$, то $M[\varepsilon | A]$ удовлетворяет свойствам безусловного математического ожидания и если $\{A_K\}$ есть полная группа событий в $\Omega$, то  
$$M[\varepsilon] = \sum_k P(A_k) M[\varepsilon | A_k]$$  
Доказательство:  
Первая часть доказывается напрямую, вторая часть следует из:  
$$M[\varepsilon] = M [\varepsilon\sum_k I_{A_K}] = \sum_kM [\varepsilon I_{A_k}] = \sum_k (A_k) M[\varepsilon | A_k]$$  
Вероятность вводится как частный случай:  
$$P(B|A) = M[I_B | A] = \frac{M[I_A I_B]}{M[I_A]} = \frac{P(AB)}{P()A}$$  
По смыслу условная вероятность соответствует доле внутри выделенного множества $A \subset \Omega$  
Данное соотношение можно переписать в виде  
$$P(AB) = P(A) P(B|A)$$  
которое верно и при $P(A) = 0$   
Кроме того   
$$P(A|B) = \frac{P(A)P(B|A)}{P(B)}$$  
Частным случаем теоремы будет соотношение:  
$$P(B = \sum_k P(A_k) P(B| A_k)$$  Которое хорошо известно как формула полной вероятности  
Здесь $\{A_k\}$ - полная группа событий.   

## Формула Байеса  
Комбинируя эти 2 соотношения, получим формулу Байеса  
$$P(A_i | B) = \frac{P(A_i)P(B|A_i)}{\sum_k P(A_k)P(B|A_k)}$$  
$P(A_i)$ - априорная вероятность события $A_i$  
$P(A_i | B)$ - апостериорная вероятность события $A_i$   
