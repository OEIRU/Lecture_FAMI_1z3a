$$P(I(x-x_{i})=1)=P(x_{i}\leq x)=F(x)$$  
Случайная величина $K = \sum_{i=1}^{n}I(x-x_{i})$ имеет распределение:  
$$M[k]=np=nF(x)$$  
$$D[K]=np(1-p)=nF(x)(1-F(x))$$  
$$M[\hat{F}(x)]=\frac{1}{n}M[K]=F(x) \text{ - несмещенность}$$  
$$D[\hat{F}(x)]=\frac{1}{n }F(x)(1-F(x))$$  
Дисперсия достигает максимума   
$$D[\hat{{F}(x)}]=\frac{0.25}{n} \text{ при } F(x)=\frac{1}{2}$$  
Что соответствует медиане.   
  
## 2. Эффективность.  
Оценка должна обладать $min$ рассеянием  
$$\hat{D}(\theta)=M[(\hat{\theta}-\theta)^2]=min$$  
Если оценка несмещенная, то это означает $min$ дисперсии асимптотическое.  
Эффективность при $n \to \infty$   
СКО:  
$$\sqrt{\hat{D}(\theta)}=\sqrt{ M[(\hat{\theta}-\theta)^2] }$$  
Какую оценку предпочесть:  
+ Несмещенную, но с большей дисперсией  
+ Смещенную с меньшей дисперсией  

Т.к смещение - составная часть СКО, то оно приемлемо до тех пор, пока малО по сравнению с СКО. Но когда несколько равноценных оценок складываются независимо, смещение остается постоянным, а составляющая СКО, обусловленная дисперсией, обратно пропорционально квадратному корню из числа оценок  
$\to$ СКО полностью определяется смещением.   
За счет повышения смещения ... понижается дисперсия.  

Для нормально распределения с неизвестным средним  
$$S^2 = \frac{1}{n} \sum_{i=1}^{n}(x_{i}-\overline{x})^2$$ $$\hat{D}(S^2)=\frac{2n-1}{n^2}\sigma^4 $$
меньше дисперсии несмещенной оценки   
$$S^2_{i}=\frac{1}{n-1}\sum_{{i=1}}^{n}(x_{i}-\overline{x})^2$$  
 $$\hat{D}(S^2_{i})=\frac{2}{n-1}\sigma^4 $$  
## 4. Достаточность  
Некоторые статические модели позволяют заменить выборку $X = (x_{1},\dots, x_{n})$ на статистику $T(x)$ - эквивалент всей выборки при оценивании $\theta$.   
$\to$ сжатие информации до некоторой функции от выборки.   
  
Схема Бернулли:   
$$P(X_{i}=x_{i})=\theta^{x_{i}}(1-\theta)^{1-x_{i}}, x_{i} \in (0.1)$$  
Совместное распределение выборки:  
$$P\left( \prod_{i=1}^{n} X_{i}=x_{i}\right)=\prod P(X_{i}=x_{i})=\prod\theta^{x_{i}}(1-\theta)^{1-x_{i}}=\theta^{\sum x_{i}}(1-\theta)^{\sum (1-x_{i})}=$$  
$$=\theta^t(1-\theta)^{n-t}$$  
$$t=T(x)=\sum_{i=1}^n X_{i}$$  
Условное распределение выборки X при условии $T(x)=t; t = 0,\dots,n$ **не зависит от $\theta$**   
$$P(X=x|T(x)=t)=\frac{\theta^t (1-\theta)^{n-t}}{C_{n}^{t}\theta^{t}(1-\theta)^{n-t}}=\frac{1}{C_{n}^t}$$  
  
Статистика  
$$T(x)=(T_{1}(x),\dots, T_{m}(x))$$  
в дискретной модели называется **достаточной**, если $\forall\theta\in\Theta,x\in R^{n}$ любых возможных значений $t=(t_{1},\dots,t_{m})$ условная вероятность $P(X=x|T(x)=t)$ не зависит от $\theta$.  
  
Как для заданной статистической модели найти достаточную статистику?  
**Критерий факторизации**  
Векторная статистика $T$ в дискретной модели достигается тогда и только тогда, когда существуют только функции $g$ и $h$:  
$$f(x, \theta)=g(T(x), \theta)h(x) \text{, где } f(x, \theta) \text{ совместная вероятность выборки}$$  
Для схемы Бернулли:  
$$g(t, \theta)= \theta^t (1-\theta)^{n-t}; \text{ }h(x)=1; \text{ }t=\sum x_{i}$$  
Для непрерывных моделей $f(x, \theta)$ - совместная плотность выборки.   
Достаточная статистика, если дана факторизация плотности в виде (x)  
  
Неравенство Рао-Крамера:  
Для несмещенных оценок и оценок с постоянным смещением рассеяния (дисперсии) оценки удовлетворяет:  
$$D_{{\theta}[}[\hat{\theta}]\geq \frac{1}{M\left( \frac{d}{d\theta}\ln(\theta,x) \right)^2}$$  
При выполнении условий регулярности.   
где $L(\theta,x)=f(x|\theta)$ функция правдоподобия как функция от параметра при фиксированной выборке. Знак равенства достигается только для **эффективных оценок**   
**Пример:**   
$$x_{i} \sim N()\theta, \sigma^2)$$  
Оценка $\overline{x}$ с дисперсией $\frac{\sigma^2}{n}$ - эффективная.  
Погрешность оценки $\sqrt{D \hat{\theta} }$ не может уменьшаться быстрее, чем $\frac{C}{\sqrt{ n }}$   
  
**Контрпример**:  
X(n) - максимум выборки из равномерного распределения на $[0, \theta]$, который оценивает $\theta$ с точностью порядка $\frac{1}{n}$   
$\to$ сверхэффективная оценка.   
  
Условия, при которых неравенство Рао-Крамера обращается в равенство:  
$$\frac{d}{d\theta}\ln L (\theta, x)=\eta(\theta)(\hat{\theta}-\theta)(* *)$$  
Это выражение не зависит от $\hat{\theta}$ и выборки, если $\hat{\theta}$ достаточное. (???)  
  
Критерий существования несмещенной эффективности оценки - 2 условия   
1. Достаточность  
2. Выполнение ($**$)   
  
Информационное количество Фишера  
$$I_{{n}}(\theta)=M\left[ \left( \frac{d}{d\theta}\ln L(\theta,x) \right)^2 \right]=-M\left[ \frac{d}{d\theta}\ln L(\theta,x) \right]$$  
Среднее количество информации об оцениваемом параметре, содержащейся в выборке    
$$D_{ef}(\theta)=\frac{1}{I_{n}}=\frac{1}{nI_{1(\theta)}}$$  
## Методы оценивания параметров:  
1. Графический  
2. ММ - моментов  
3. ММП - максимальной правдоподобности  
  
  
Подробнее о графическом:  
Вероятностная бумага позволяет представить несмещенную теоретическую функцию распределения в виде прямой  
$$F^{-1}(F(x))=x \text{ - квартиль распределения}$$  
По оси x - выборочное значение по оси $F^{-1} (\hat{F}(x_i)))$ (график ggplot)  
  
Нужен для грубого определения оценок, подходит для моделей сдвиг-масштаба с помощью линейной аппроксимации можно получить оценки параметров сдвига и масштаба.   
